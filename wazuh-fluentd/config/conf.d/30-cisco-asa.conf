###################### Cisco ASA Configuration ######################
# Port: 30517 UDP
# Pipeline: cisco-asa

<worker 0>
<source>
  @type udp
  port 40517
  bind 0.0.0.0
  tag cisco.asa
  <parse>
    @type regexp
    expression /^(?<message>.*)$/
  </parse>
  source_address_key source_ip
</source>
</worker>

# Add metadata and enrich
<filter cisco.asa.**>
  @type record_transformer
  enable_ruby true
  <record>
    log_source cisco
    vendor cisco
    product asa
    hostname ${record["source_ip"] || "unknown"}
    "@timestamp" ${time.strftime('%Y-%m-%dT%H:%M:%S.%LZ')}
  </record>
</filter>

# Send to OpenSearch/Wazuh Indexer
<match cisco.asa.**>
  @type opensearch
  
  # Connection settings
  host "#{ENV['INDEXER_HOST'] || 'wazuh-indexer'}"
  port "#{ENV['INDEXER_PORT'] || '9200'}"
  scheme https
  ssl_verify false
  ssl_version TLSv1_2
  
  # Authentication
  user "#{ENV['INDEXER_USERNAME']}"
  password "#{ENV['INDEXER_PASSWORD']}"
  
  # Index settings
  index_name anki-cisco-asa-%Y.%m.%d
  
  # Use pipeline in OpenSearch for parsing
  pipeline cisco-asa
  
  # Buffering
  <buffer tag, time>
    @type file
    path /fluentd/buffer/cisco-asa
    timekey 60s
    timekey_wait 10s
    flush_mode interval
    flush_interval 10s
    retry_type exponential_backoff
    retry_wait 1s
    retry_max_interval 60s
    retry_timeout 1h
    flush_at_shutdown true
    chunk_limit_size 8MB
    total_limit_size 512MB
    overflow_action drop_oldest_chunk
  </buffer>
  
  # Error handling
  <secondary>
    @type file
    path /fluentd/failed_records/cisco-asa
  </secondary>
</match>
