###################### Generic Syslog Configuration ######################
# Port: 30519 UDP, 30520 TCP
# Pipeline: generic-syslog
# Catch-all for other syslog sources

<worker 3>
  <source>
    @type udp
    port 40519
    bind 0.0.0.0
    tag generic.syslog
    <parse>
      @type regexp
      expression /^(?<message>.*)$/
    </parse>
    source_address_key source_ip
  </source>

  <source>
    @type tcp
    port 40520
    bind 0.0.0.0
    tag generic.syslog
    <parse>
      @type regexp
      expression /^(?<message>.*)$/
    </parse>
  </source>
</worker>

# Add metadata and enrich
<filter generic.syslog.**>
  @type record_transformer
  enable_ruby true
  <record>
    log_source generic
    vendor unknown
    product syslog
    hostname ${record["source_ip"] || "unknown"}
    "@timestamp" ${time.strftime('%Y-%m-%dT%H:%M:%S.%LZ')}
  </record>
</filter>

# Send to OpenSearch/Wazuh Indexer
<match generic.syslog.**>
  @type opensearch
  
  # Connection settings
  host "#{ENV['INDEXER_HOST'] || 'wazuh-indexer'}"
  port "#{ENV['INDEXER_PORT'] || '9200'}"
  scheme https
  ssl_verify false
  ssl_version TLSv1_2
  
  # Authentication
  user "#{ENV['INDEXER_USERNAME']}"
  password "#{ENV['INDEXER_PASSWORD']}"
  
  # Index settings
  index_name anki-generic-syslog-%Y.%m.%d
  
  # Use pipeline in OpenSearch for parsing
  pipeline generic-syslog
  
  # Buffering
  <buffer tag, time>
    @type file
    path /fluentd/buffer/generic-syslog
    timekey 60s
    timekey_wait 10s
    flush_mode interval
    flush_interval 10s
    retry_type exponential_backoff
    retry_wait 1s
    retry_max_interval 60s
    retry_timeout 1h
    flush_at_shutdown true
    chunk_limit_size 8MB
    total_limit_size 512MB
    overflow_action drop_oldest_chunk
  </buffer>
  
  # Error handling
  <secondary>
    @type file
    path /fluentd/failed_records/generic-syslog
  </secondary>
</match>
