###################### NetFlow Configuration ######################
# Port: 2055 UDP
# Flow:
#   - ALL NetFlow data â†’ Wazuh Manager (rules) + Indexer (anki-netflow-*)
#   - Filebeat filters out sensor logs from archives
#   - Agent logs preserved in wazuh-archives-*

<source>
  @type netflow
  bind 0.0.0.0
  port 2055
  tag netflow.event
  cache_ttl 6000
  versions [5, 9, 10]
</source>

# Add metadata and enrich
<filter netflow.**>
  @type record_transformer
  enable_ruby true
  <record>
    log_source netflow
    vendor multi
    product netflow
    data_source anki-sensor           # Tag for Filebeat filtering
    "@timestamp" ${time.strftime('%Y-%m-%dT%H:%M:%S.%LZ')}
    observer { "product": "NetFlow", "vendor": "Multi", "type": "network" }
    
    # NetFlow specific fields
    src_ip ${record["ipv4_src_addr"] || record["ipv6_src_addr"] || "unknown"}
    dst_ip ${record["ipv4_dst_addr"] || record["ipv6_dst_addr"] || "unknown"}
    src_port ${record["l4_src_port"] || 0}
    dst_port ${record["l4_dst_port"] || 0}
    protocol ${record["protocol"] || "unknown"}
    bytes ${record["in_bytes"] || record["out_bytes"] || 0}
    packets ${record["in_pkts"] || record["out_pkts"] || 0}
    
    # Flow metadata
    flow_start ${record["flowStartMilliseconds"] || record["first_switched"] || "unknown"}
    flow_end ${record["flowEndMilliseconds"] || record["last_switched"] || "unknown"}
    exporter_ip ${record["host"] || "unknown"}
  </record>
</filter>

# Send ALL NetFlow data to BOTH Wazuh Manager and Indexer
<match netflow.**>
  @type copy
  
  # To Wazuh Manager for rule processing
  <store>
    @type rawtcp
    
    host "#{ENV['WAZUH_MANAGER_HOST'] || 'wazuh-manager'}"
    port "#{ENV['WAZUH_MANAGER_PORT'] || '1533'}"
    
    <format>
      @type json
    </format>
    
    <buffer>
      @type file
      path /fluentd/buffer/netflow-wazuh
      flush_mode interval
      flush_interval 5s
      retry_type exponential_backoff
      retry_wait 2s
      retry_max_interval 60s
    </buffer>
  </store>
  
  # To Indexer for flow analysis
  <store>
    @type opensearch
    
    host "#{ENV['INDEXER_HOST'] || 'wazuh-indexer'}"
    port "#{ENV['INDEXER_PORT'] || '9200'}"
    scheme https
    ssl_verify false
    ssl_version TLSv1_2
    
    user "#{ENV['INDEXER_USERNAME']}"
    password "#{ENV['INDEXER_PASSWORD']}"
    
    index_name anki-netflow-%Y.%m.%d
    type_name _doc
    
    <buffer tag, time>
      @type file
      path /fluentd/buffer/netflow-indexer
      timekey 60s
      timekey_wait 10s
      flush_mode interval
      flush_interval 10s
      retry_type exponential_backoff
      retry_wait 2s
      retry_max_interval 300s
      retry_timeout 24h
      chunk_limit_size 8MB
      total_limit_size 1GB
      overflow_action drop_oldest_chunk
      compress gzip
    </buffer>
    
    <secondary>
      @type file
      path /fluentd/failed_records/netflow-indexer
    </secondary>
  </store>
</match>
